---
title: "Automated Residual Plot Assessment with the R Package autovi and the Shiny App autovi.web"
format:
  quarto-anzjs-pdf:
    keep-tex: true  
    shorttitle: "Automated Residual Plot Assessment"
    double-space: true
    line-numbers: true
    # You can specify extra preamble in the file below.
    include-in-header:
      - header.tex
date: today
date-format: "YYYY" # used to define volumeyear
author:
  - name: Weihao Li
    email: patrick.li@anu.edu.au
    corresponding: true
    affiliations:
      - name: Monash University
        department: Department of Econometrics and Business Statistics
        address: Wellington Road, VIC 3800, Australia
      - name: The Australian National University
        department: Biological Data Science Institute
        address: 46 Sullivan's Creek Road, ACT 2600, Australia
    orcid: 0000-0003-4959-106X
  - name: Dianne Cook
    email: dicook@monash.edu 
    affiliations:
      - name: Monash University
        department: Department of Econometrics and Business Statistics
        address: Wellington Road, VIC 3800, Australia
    orcid: 0000-0002-3813-7155
  - name: Emi Tanaka
    email: emi.tanaka@anu.edu.au
    affiliations: 
      - name: The Australian National University
        department: Biological Data Science Institute
        address: 46 Sullivan's Creek Road, ACT 2600, Australia
    orcid: 0000-0002-1455-259X
  - name: Susan VanderPlas
    email: emi.tanaka@anu.edu.au
    affiliations:
      - name: University of Nebraska
        department: Department of Statistics
        address: Hardin Hall, 3310 Holdrege St Suite 340, Lincoln, NE 68583, United States
    orcid: 0000-0002-3803-0972
  - name: Klaus Ackermann
    email: Klaus.Ackermann@monash.edu 
    affiliations:
      - name: Monash University
        department: Department of Econometrics and Business Statistics
        address: Wellington Road, VIC 3800, Australia
    orcid: 0000-0001-7693-8538
# Note that the Journal requires that a paper must begin with a
# "Summary" not an "Abstract".  This is automatically taken care
# of by the anzsauth document style.  So even though the following
# says "abstract" the heading "Summary" will appear in
# the processed version.
abstract: |
  Visual assessment of residual plots is a common approach for diagnosing linear models, but it relies on manual evaluation, which does not scale well and can lead to inconsistent decisions across analysts. The lineup protocol, which embeds the observed plot among null plots, can reduce subjectivity but requires even more human effort. In today’s data-driven world, such tasks are well-suited for automation. We present a new R package that uses a computer vision model to automate the evaluation of residual plots. An accompanying Shiny app is provided for ease of use. Given a sample of residuals, the model predicts a visual signal strength (VSS) and offers supporting information to help analysts assess model fit. 
# Note that "keywords" should not include words and phrases
# that form part of the title of the paper.
# Also keywords (with the exception of proper names and
# certain abbreviations that conventionally appear all in
# capital letters) should *not* be capitalised.
keywords: [initial data analysis, statistical graphics, data visualization, visual inference, computer vision, machine learning, hypothesis testing, regression analysis, model diagnostics]
bibliography: bibliography.bib  
#nocite: |
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  echo = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "100%", 
  fig.align = "center")
```

# Introduction {#sec-autovi-introduction}

Regression analysis is a widely used statistical modeling technique for data in many fields. There is a vast array of software for conducting regression modeling and generating diagnostics. The package `lmtest` [@lmtest] provides a suite of conventional tests, while the `stats` package [@stats] offers standard diagnostic plots such as residuals vs. fitted values, quantile-quantile (Q-Q) plots, and residuals vs. leverage plots. Additional packages like `jtools` [@jtools], `olsrr` [@olsrr], `rockchalk` [@rockchalk], and `ggResidpanel` [@ggresidpanel] deliver similar graphical diagnostics, often with enhanced aesthetics or interactive features. These tools collectively produce the core diagnostic plots outlined in the classical text by @cook1982residuals. The `ecostats` package [@warton_global_2023] extends these diagnostics by incorporating simulation envelopes into residual plots. Meanwhile, `DHARMa` [@dharma] compares empirical quantiles (0.25, 0.5, and 0.75) of scaled residuals to their theoretical counterparts, with a strong focus on identifying model violations such as heteroscedasticity, misspecified functional forms, and issues specific to generalized linear and mixed-effect models, like over/under-dispersion. It also provides conventional test annotations to reduce the risk of misinterpretation.

However, relying solely on subjective assessments of these plots can lead to issues such as over-interpreting random patterns as model violations. @li2024plot demonstrated that visual inference methods, particularly those using the lineup protocol [@buja2009statistical], offer more practical and reliable assessments of residual patterns than conventional tests, as they are less sensitive to minor departures. Packages such as `nullabor` [@nullabor], `HLMdiag` [@loy2014hlmdiag], and `regressinator` [@regressinator] support this approach by enabling users to compare observed residual plots with plots generated under null hypothesis, thereby helping to quantify the significance of any detected patterns.

As noted in @li2024automated, the lineup protocol has significant limitations in large-scale applications due to its reliance on human labor. To overcome this constraint, a computer vision model was developed alongside a corresponding statistical testing procedure to autmoate the assessment of residual plots. The model takes as input a residual plot and a set of auxiliary variables (such as the number of observations) and outputs a predicted visual signal strength (VSS). This VSS estimates the degree of deviation between the residual distribution of the fitted model and the reference distribution expected under correct model specification.

To make the statistical testing procedure and trained computer vision model widely accessible, we developed the R package `autovi` along with a companion web interface, `autovi.web`, which allows users to automatically assess their residual plots using the trained computer vision model.

The remainder of this paper is structured as follows: @sec-vss-desc introduces the definition and computation of visual signal strength. @sec-autovi provides a detailed documentation of the `autovi` package, including its usage and infrastructure. @sec-autovi-web focuses on the `autovi.web` interface, describing its design and usage, along with illustrative examples. Finally, @sec-autovi-conclusion presents the main conclusions of this work.

# Definition and computation of visual signal strength {#sec-vss-desc}

To train a computer vision model, a measure of the visible pattern in a plot is needed. We call this the **visual signal strength** (VSS), which measures how prominently a specific set of visual patterns appears in an image. This can be computed for a training set of data, and plots, where the generating distributions are specified.

In the context of regression model diagnostics, VSS describes the clarity of visual patterns on a diagnostic plot that may indicate model violations. Violations can be categorized as weak, moderate, or strong, but here we treat it as a continuous positive real variable. Importantly, its interpretation depends on how it is linked to a function of the data or the underlying data generating process. Consequently, the calculation of VSS can vary across different model classes or within the same model, depending on the generating function.

VSS estimates the distance between the residual distribution of a fitted classical normal linear regression model and a reference distribution [see @li2024automated, for details]. The distance measure is based on the Kullback-Leibler (KL) divergence:

\begin{equation*} \label{eq:kl-0}
D = \log\left(1 + D_{KL}\right),
\end{equation*}

where $D_{KL}$ is given by:

\begin{equation} \label{eq:kl-1}
D_{KL} = \int_{\mathbb{R}^{n}}\log\frac{p(\boldsymbol{e})}{q(\boldsymbol{e})}p(\boldsymbol{e})d\boldsymbol{e},
\end{equation}

here, $p(.)$ and $q(.)$ are the probability density functions of the reference residual distribution $P$ and the true residual distribution $Q$, respectively.

This distance measure depends on knowledge of the true residual distribution, which is unknown in practice. To compute $D_{KL}$ for the training samples, Equation \ref{eq:kl-1} takes different forms depending on the specific model violations. For instance, where necessary higher-order predictors, $\boldsymbol{Z}$, and their corresponding parameter, $\boldsymbol{\beta}_Z$, are omitted from the fitted linear model, the distance measure can be expanded as follows:

\begin{equation*} \label{eq:kl-2}
D_{KL} = \frac{1}{2}\left(\boldsymbol{\mu}_z^\top(\text{diag}(\boldsymbol{R}\sigma^2))^{-1}\boldsymbol{\mu}_z\right),
\end{equation*}

where $\boldsymbol{\mu}_z = \boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z$, $\boldsymbol{R} = \boldsymbol{I}_n - \boldsymbol{X}(\boldsymbol{X}^\top\boldsymbol{X})^{-1}\boldsymbol{X}^\top$ and $\boldsymbol{X}$ is the design matrix of the regression model. 

The computer vision model approximates this mapping from a set of residuals to its corresponding distance measure. It is trained on a large number of synthetic regression models, each designed to simulate specific violations of classical linear regression assumptions. These models incorporate non-linearity through Hermite polynomial transformations of predictors, heteroskedasticity by making the error variance a predictor-dependent function, and non-normality by drawing residuals from distributions such as discrete, uniform, and lognormal. Both simple and multiple linear regression structures are used, with controlled parameters to generate diverse and complex residual patterns. Since the data-generating process is known, the distance measure $D$ can be explicitly calculated, enabling supervised training. The computer vision model takes a residual plot as input and outputs the corresponding distance measure, learning to quantify model violations directly from visual patterns. Additional details are provided in @li2024automated.

# Definition and simulation of null and bootstrapped residuals {#sec-null-and-boot-desc}

In the subsequent sections, we will frequently refer to null residuals and bootstrapped residuals, so it is helpful to first define and explain how they are generated.

**Null residuals** are used to generate null plots within the lineup protocol framework, serving as the foundation for the statistical testing in our automated residual plot assessment. Specifically, they represent residuals generated under the null hypothesis that the model is correctly specified. A common method for simulating null residuals in linear regression involves sampling from a normal distribution with mean zero and variance equal to the estimated variance of the error term. These simulated residuals and their corresponding plots depict what one would expect from a correctly specified model. If the true residual plot exhibits noticeable deviations from these null plots, it may suggest model misspecification.

Our computer vision model is trained to assign lower VSS to null plots and higher VSS to plots that display distinct patterns. Accordingly, statistical testing is performed by computing the proportion of null plots whose VSS equals or exceeds that of the observed residual plot. This proportion serves as a p-value for a one-sided hypothesis test.

**Bootstrapped residuals** are obtained by refitting the model on bootstrap samples, which are generated by sampling individual observations with replacement from the original dataset. The residual plots obtained from these refitted models are evaluated using the same computer vision model. The predicted VSS from the bootstrapped plots provide an empirical estimate of the variation in the VSS of the observed residual plot. By examining the proportion of bootstrapped plots that also exhibit significant violations, we can assess whether the original conclusion is robust to sampling variability.

# R package: autovi {#sec-autovi}

The main purpose of `autovi` is to provide rejection decisions and $p$-values for testing the null hypothesis ($H_0$) that the regression model is correctly specified. The package provides automated interpretation of residual plots using computer vision. The name `autovi` stands for **auto**mated **v**isual **i**nference. This functionality can be accessed through the R package `autovi`, or through a web interface, `autovi.web`, which enables users to perform analyses without installing R, Python, or their associated dependencies locally.

## Motivation {#sec-why}

@fig-three-examples shows three sets of plots of residuals against fitted values. The simulated example in (a) might be interpreted as a heteroscedastic pattern, however the automated reading would predict this to have a visual signal strength (VSS) of 1.53, with a corresponding $p$-value of 0.25. This means it would be interpreted as a good residual plot, that there is nothing in the data to indicate a violation of model assumptions. Skewness in the predictor variables is generating the apparent heteroscedasticity, where the smaller variance in residuals at larger fitted values is due to smaller sample size only. The Breusch-Pagan test  [@breusch1979simple] for heteroscedasticity would also not reject this as good residual plot.

The data in (b) is generated by fitting a linear model predicting `mpg` based on `hp` using the `datasets::mtcars`. It is a small data set, and there is a hint of nonlinear structure not captured by the model. The automated plot reading would predict a VSS of 3.57, which has a $p$-value less than 0.05. That is, the nonlinear structure is most likely real, and indicates a problem with the model. The conventional test, a Ramsey Regression Equation Specification Error Test (RESET) [@ramsey1969tests] would also strongly detect the nonlinearity. 

The third example is generated using the `surreal` package [@surreal], where structure residuals are embedded in the data. In this case, a quote inspired by Tukey, "visual summaries focus on unexpected values", is used to define the residual structure. The automated plot reading predicts the VSS to be 5.87, with a $p$-value less than 0.05. Visually, the structure is strikingly clear, but a RESET test for nonlinear structure would not report a problem. (It would be detected by a Breusch-Pagan for heteroscedasticity and also Shapiro-Wilk test [@shapiro1965analysis] for non-normality.)

```{r}
#| label: fig-three-examples
#| fig-cap: "Reading residual plots can be a difficult task, particularly for students new to statistical modeling. The \\texttt{autovi} package makes it easier. Here are three examples of residual plots, which may appear to have structure. According to autovi, the visual signal strengths (VSS) of these three examples are approximately (a) 1.53, (b) 3.57, (c) 5.87, resulting in (b), (c) being significant violations of good residuals, but (a) is consistent with a good residual plot."
#| fig-width: 12
#| fig-height: 4
#| out-width: 100%
library(readr)
library(dplyr)
library(ggplot2)
library(patchwork)
library(ggthemes)

test_resid <- read_csv("residuals/test_resid.csv")
p1 <- ggplot(test_resid, aes(x=.fitted, y=.resid)) +
  geom_hline(yintercept=0, colour="red") + 
  geom_point() + 
  ggtitle("(a) simulated") +
  theme_base(base_size = 12) + 
  theme(aspect.ratio = 1.1, 
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        plot.background = element_rect(fill = NA, 
                                       colour = NA))

mtcars_all2 <- read_csv("residuals/mtcars_all2.csv")
p2 <- ggplot(mtcars_all2, aes(x=.fitted, y=.resid)) +
  geom_hline(yintercept=0, colour="red") + 
  geom_point() + 
  ggtitle("(b) mtcars") +
  theme_base(base_size = 12) + 
  theme(aspect.ratio = 1.1, 
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        plot.background = element_rect(fill = NA, 
                                       colour = NA))

sur_all <- read_csv("residuals/sur_all.csv")
p3 <- ggplot(sur_all, aes(x=.fitted, y=.resid)) +
  geom_hline(yintercept=0, colour="red") + 
  geom_point() + 
  ggtitle("(c) surreal") +
  theme_base(base_size = 12) + 
  theme(aspect.ratio = 1.1, 
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        plot.background = element_rect(fill = NA, 
                                       colour = NA))

p1 + p2 + p3 + plot_layout(ncol=3)
```

## Implementation {#sec-autovi-implementation}

The `autovi` package is built on the `bandicoot` object-oriented programming (OOP) system [@bandicoot], marking a departure from R’s traditional S3 generic system. This OOP architecture enhances flexibility and modularity, allowing users to redefine key functions through method overriding.
 
The `autovi` infrastructure effectively integrates multiple programming languages and libraries into a comprehensive analytical tool. It relies on five core libraries from Python and R, each playing a critical role in the analysis pipeline. In Python, `pillow` [@clark2015pillow] handles image processing tasks such as reading and resizing PNG files of residual plots, then converting them into input tensors for further analysis. `TensorFlow` [@abadi2016tensorflow], a key component of modern machine learning, is used to predict the VSS of these plots using a pre-trained convolutional neural network.

In the R environment, `autovi` utilizes several libraries. `ggplot2` [@ggplot2] generates the initial residual plots, saved as PNG files for visual input. `cassowaryr` [@mason2022cassowaryr] computes scagnostics (scatter plot diagnostics), providing numerical features that capture statistical properties of the plots. These scagnostics complement the visual analysis by offering quantitative metrics as secondary input to the computer vision model. `reticulate` [@reticulate]  enables seamless communication between R and Python.

## Installation

The `autovi` package is available on CRAN. It is actively developed and maintained, with the latest updates accessible on GitHub. This paper uses `autovi` version 0.4.2.
The package includes internal functions to check the current Python environment used by the `reticulate` package. If the necessary Python packages are not installed in the Python interpreter, an error will be raised. If you want to select a specific Python environment, you can do so by calling the `reticulate::use_python()` function before using the `autovi` package. 

We recommend using the Shiny app `autovi.web` if users encounter installation problems. 

## Usage {#sec-autovi-usage}

### Numerical summary {#sec-autovi-numerical}

Three steps are needed to get an automated assessment of a set of residuals and fitted values: 

1. Load the `autovi` package using the `library()` function.
2. Create a checker object with a linear regression model.
3. Call the `check()` method of the checker, which, by default, predicts the VSS for the true residual plot, 100 null plots, and 100 bootstrapped plots. The method stores the predictions internally and prints a concise results report. 

The code to do this is:

```{r}
#| echo: false
set.seed(10086)
```

```r
library(autovi) 
checker <- residual_checker(lm(dist ~ speed, data = cars))
checker$check() 
```

It produces the following summary:

```{r}
library(autovi)
checker <- auto_vi(fitted_model = lm(dist ~ speed, data = cars))
```

```{r message=TRUE}
if (!file.exists("cached_data/autovi_checker_demo_print.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  checker$check()
  saveRDS(checker$..str..(), "cached_data/autovi_checker_demo_print.rds")
} else {
  cli::cli_h3(readRDS("cached_data/autovi_checker_demo_print.rds"))
}
```


```{r}
if (!file.exists("cached_data/autovi_check_demo.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  checker$check()
  saveRDS(checker$check_result, "cached_data/autovi_check_demo.rds")
} else {
  checker$check_result <- readRDS("cached_data/autovi_check_demo.rds")
}
```

The summary includes observed VSS of the true residual plot and associated $p$-value of the automated visual test. The $p$-value is the proportion of null plots (out of the total 100) that have VSS greater than or equal to that of the true residual plot. The report also provides sample quantiles of VSS for null samples and bootstrapped data plots, providing more information about the sampling variability and a likelihood of model violations. The likelihood is computed from the proportion of values greater than the observed VSS in both the bootstrapped data values and the simulated null values.

### Visual summary {#sec-autovi-visual}

Users can visually inspect the original residual plot alongside a sample null plot using `plot_pair()` or a lineup of null plot `plot_lineup()`. This visual comparison can clarify why $H_0$ is either rejected or not, and help identify potential remedies. 

```{r fig-plot-pair, echo = TRUE, fig.height=2, fig.width=3, out.width="60%", fig.cap="True plot alongside one null plot, for quick comparison."}
checker$plot_pair()
```

The `plot_pair()` method (@fig-plot-pair) displays the true residual plot on the left and a single null plot on the right. If a full lineup was shown, the true residual plot would be embedded in a page of null plots. Users should look for any distinct visual patterns in the true residual plot that are absent in the null plot. Running these functions multiple times can help any visual suspicions, as each execution generates new random null plots for comparison.

The package offers a straightforward visualization of the assessment result through the `summary_plot()` function.

```{r fig-summary-plot, echo = TRUE, fig.height=3, fig.width=6, fig.cap="Summary plot comparing the densities of VSS for bootstrapped residual samples (red) relative to VSS for null plots (blue)."}
checker$summary_plot()
```

In the result, shown in @fig-summary-plot, the blue area represents the density of VSS for null residual plots, while the red area shows the density for bootstrapped residual plots. The dashed line indicates the VSS of the true residual plot, and the solid line marks the critical value at a 95% significance level. The $p$-value and the likelihood ratio are displayed in the subtitle. The likelihood ratio represents the ratio of the likelihood of observing the VSS of the true residual plot from the bootstrapped distribution compared to the null distribution.

Interpreting the plot involves several key aspects. If the dashed line falls to the right of the solid line, it suggests rejecting the null hypothesis. The degree of overlap between the red and blue areas indicates similarity between the true residual plot and null plots; greater overlap suggests more similarity. Lastly, the portion of the red area to the right of the solid line represents the percentage of bootstrapped models considered to have model violations.

This visual summary provides an intuitive way to assess the model's fit and potential violations, allowing users to quickly grasp the results of the automated analysis.


## Modularized infrastructure {#sec-autovi-infrastructure}

```{r out.width = "100%"}
#| label: fig-autovi-diag
#| fig-cap: "Diagram illustrating the infrastructure of the R package \\texttt{autovi}. The modules in green are primary inputs provided by users. Modules in blue are overridable methods that can be modified to accommodate users' specific needs. The module in yellow is a pre-defined non-overridable method. The modules in red are primary outputs of the package."
magick::image_read_pdf("figures/autovi.pdf")
```

The initial motivation for developing `autovi` was to create a convenient interface for sharing the models described and trained in @li2024automated. However, recognizing that the classical normal linear regression model represents a restricted class of models, we sought to avoid limiting the potential for future extensions, whether by the original developers or other developers. As a result, the package was designed to function seamlessly with linear regression models with minimal modification and few required arguments, while also accommodating other classes of models through partial infrastructure substitution. This modular and customizable design allows `autovi` to handle a wide range of residual diagnostics tasks.

The infrastructure of `autovi` consists of ten core modules: data extraction, bootstrapping and model refitting, fitted values and residuals extraction, auxiliary computation, null residual simulation, plotting, plot saving, image reading and resizing, VSS prediction, and $p$-value computation. Each module is designed with minimal dependency on the preceding modules, allowing users to customize parts of the infrastructure without affecting its overall integrity. An overview of this infrastructure is illustrated in @fig-autovi-diag.

The package takes regression models and a `Keras` model as primary inputs. Modules for VSS prediction and $p$-value computation are fixed but accessible via function arguments, using `TensorFlow` for inference and statistical testing. The image loading module is also fixed, using `PIL` to read and resize images based on the `Keras` model’s input shape. The remaining seven modules are overridable, allowing users to adapt the workflow as needed. The data extraction module extracts a `data.frame` containing variables used in the regression model. The bootstrapping and refitting module resamples the data and refits the model. The fitted values and residuals extraction module returns these values as a `data.frame`. The auxiliary computation module calculates scagnostics such as monotonicity. The plotting module generates a `ggplot` in a standard format, and the plot saving module exports it at the same resolution as the training images. These modules are described in detail in the package documentation.

## Extension to Other Model Classes

The `autovi` R package can be extended to accommodate other classes of models beyond linear regression, such as generalized linear models (`glm`). This is achieved by substituting the relevant overridable modules, and if needed, supplying a different `Keras` model.

We provide an example of defining a new checker class tailored for Poisson regression using the `glm` framework:

1. Define a new class using `new_class()` with `AUTO_VI` as the parent class.
2. Override the necessary methods using `register_method()`. In this example, we use Pearson residuals. To simulate null residuals, we assume the fitted model is correct and the estimated coefficients are accurate. New response values are generated accordingly, and a new model is fitted to this simulated response. Null residuals are then extracted from this refitted model.
3. Create an alias for the `instantiate()` method of the new class.

```{r echo = TRUE}
AUTO_POIS_VI <- new_class(AUTO_VI, class_name = "AUTO_POIS_VI")
register_method(
  AUTO_POIS_VI,
  get_fitted_and_resid = function(fitted_model = self$fitted_model) {
    tibble(.fitted = fitted(fitted_model),
           .resid = resid(fitted_model, type = "pearson"))
  },
  null_method = function(fitted_model = self$fitted_model) {
    dat <- model.frame(fitted_model)
    dat[[1]] <- rpois(nrow(dat), lambda = fitted(fitted_model))
    new_mod <- update(fitted_model, data = dat)
    return(self$get_fitted_and_resid(new_mod))
  }
)
auto_pois_vi <- AUTO_POIS_VI$instantiate
```

The resulting checker class can be employed analogously to the linear model case described in @sec-autovi-usage. For illustration, we fit a Poisson model in which the quadratic term of the predictor $x$ is intentionally omitted. This misspecification manifests as a pronounced U-shaped pattern in the lineup display, which is also successfully identified by the computer vision model, yielding a p-value substantially below the conventional threshold of 0.05.

It is important to note, however, that the pre-trained computer vision model included in `autovi`, such as `vss_phn_32` (see `list_keras_models()` for the full list of available models), was developed specifically for diagnostics of linear regression. Its applicability to other model classes relies on the assumption that the null residual plots exhibit characteristics broadly consistent with those of well-behaved linear regression residuals, that is, residuals should be approximately randomly scattered around zero, display roughly constant variance across the range of fitted values, and exhibit no discernible structure or curvature. If these conditions are not met, or if model violations do not give rise to visually detectable patterns, the validity of the automated diagnostics may be compromised. In such cases, users are encouraged to train and apply their own `Keras` models. Detailed guidance on model training and discussion on extending the methodology to other model classes can be found in @li2024automated.

```r
x <- rnorm(300, sd = 0.5)
y <- rpois(300, lambda = exp(1 + x + x^2))
pois_checker <- auto_pois_vi(
  glm(y ~ x, family = "poisson"),
  keras_model = get_keras_model("vss_phn_32")
)
pois_checker$plot_lineup()
```

```{r include = FALSE}
set.seed(10086)
x <- rnorm(300, sd = 0.5)
y <- rpois(300, lambda = exp(1 + x + x^2))
pois_checker <- auto_pois_vi(glm(y ~ x, family = "poisson"))
```

```{r}
pois_checker$plot_lineup()
```

```r
pois_checker$check()
```

```{r message = TRUE}
if (!file.exists("cached_data/autovi_glm_checker_demo_print.rds")) {
  pois_checker <- auto_pois_vi(glm(y ~ x, family = "poisson"),
                               keras_model = get_keras_model("vss_phn_32"))
  pois_checker$check()
  saveRDS(pois_checker$..str..(), "cached_data/autovi_glm_checker_demo_print.rds")
} else {
  cli::cli_h3(readRDS("cached_data/autovi_glm_checker_demo_print.rds"))
}
```


<!-- in the following sections.-->
<!-- FIXME: ET: which website? >
<!--
### Initialization

An `autovi` checker can be initialized by supplying two primary inputs, including a regression model object, such as an `lm` object representing the result of a linear regression model, and a trained computer vision model compatible with the `Keras` [@chollet2015keras] Application Programming Interface (API), to the `AUTO_VI` class constructor `auto_vi()`. The `residual_checker()` introduced in @sec-autovi-usage is a thin wrapper around `auto_vi()`, which will call `get_keras_model()` during initialization. `get_keras_model()` is a function to download a trained computer vision model (described in @li2024automated) from GitHub. “vss_phn_32” specifies a model that predicts VSS and is trained on residuals with polynomial, heteroscedasticity, and non-normality patterns (phn). More details about the hosted models will be provided in @sec-trained-model-hosting.

The input of the constructor will be stored as attributes of the checker and can be accessed by the user through the `$` operator.

```r
library(autovi)
checker <- auto_vi(fitted_model = lm(dist ~ speed, data = cars), 
                   keras_model = get_keras_model("vss_phn_32"))
```

Optionally, the user may specify the node index of the output layer of the trained computer vision model to be monitored by the checker via the `node_index` argument if there are multiple output nodes. This is particularly useful for multiclass classifiers when the user wants to use one of the nodes as a VSS indicator.

After initializing the object, you can print the checker to view its status.

```r
── <AUTO_VI object>
Status:
 - Fitted model: lm
 - Keras model: (None, 32, 32, 3) + (None, 5) -> (None, 1)
    - Output node index: 1
 - Result: UNKNOWN 
```

The status includes the list of regression model classes (as provided by the built-in `class()` function), the input and output shapes of the Keras model in the standard `Numpy` format [@harris2020array], the output node index being monitored, and the assessment result. If no check has been run yet, the assessment result will display as "UNKNOWN".

### Fitted Values and Residuals Extraction

To be able to predict VSS for a residual plot, both fitted values and residuals are needed to be extracted from the regression model object supplied by the user. In R, statistical models like `lm` (linear model) and `glm` (generalized linear model) typically support the use of generic functions such as `fitted()` and `resid()` to retrieve these values. The `get_fitted_and_resid()` method, called by the checker, relies on these generic functions by default. However, generic functions only work with classes that have appropriate method implementations. Some regression modeling packages may not fully adhere to the `stats` package guidelines for implementing these functions. In such cases, overriding the method becomes necessary.

By design, the `get_fitted_and_resid()` method accepts a regression model object as input and returns a `tibble` (a modern presentation of the `data.frame`) with two columns: `.fitted` and `.resid`, representing the fitted values and residuals, respectively. If no input is supplied, the method uses the regression model object stored in the checker. Although modules in the `autovi` infrastructure make minimal assumptions about other modules, they do require strictly defined input and output formats to ensure data validation and prevent fatal bugs. Therefore, any overridden method should follow to these conventions.

```{r echo=TRUE}
checker$get_fitted_and_resid()
```


### Data Extraction

For linear regression model in R, the model frame contains all the data required by a formula for evaluation. This is essential for bootstrapping and refitting the model when constructing a bootstrapped distribution of VSS. Typically, the model frame can be extracted from the regression model object using the `model.frame()` generic function, which is the default method used by `get_data()`. However, some regression models do not use a formula or are evaluated differently, potentially lacking a model frame. In such cases, users can either provide the data used to fit the regression model through the `data` argument when constructing the checker, or customize the method to better suit their needs. It's worth noting that this module is only necessary if bootstrapping is required, as the model frame is not used in other modules of the infrastructure.

The `get_data()` method accepts a regression model object as input and returns a `data.frame` representing the model frame of the fitted regression model. If no input is supplied, the regression model stored in the checker will be used.

```{r echo=TRUE}
checker$get_data() |> 
  head()
```


### Bootstrapping and Model Refitting

Bootstrapping a regression model typically involves sampling the observations with replacement and refitting the model with the bootstrapped data. The `boot_method()` method follows this bootstrapping scheme by default. It accepts a fitted regression model and a `data.frame` as inputs, and returns a `tibble` of bootstrapped residuals. If no inputs are provided, the method uses the regression model stored in the checker and the result of the `get_data()` method. 

Note that instead of calling `get_data()` implicitly within the method, it is used as part of the default argument definition. This approach allows users to bypass the `get_data()` method entirely and directly supply a `data.frame` to initiate the bootstrap process. Many other methods in `autovi` adopt this principle when possible, where dependencies are explicitly listed in the formal arguments. This design choice enhances the reusability and isolation of modules, offers better control for testing, and simplifies the overall process.

```{r echo=TRUE}
checker$boot_method(data = checker$get_data())
```

### Auxiliary Computation

As described in @li2024automated, in some cases, a residual plot alone may not provide enough information to accurately determine VSS. For instance, when the points in the residual plot have significant overlap, the trend and shape of the residual pattern can be difficult to discern. Including auxiliary variables, such as the number of observations, as additional inputs to the computer vision model can be beneficial. To address this, `autovi` includes internal functions within the checker that automatically detect the number of inputs required by the provided Keras model. If multiple inputs are necessary, the checker invokes the `auxiliary()` method to compute these additional inputs.

The `auxiliary()` method takes a `data.frame` containing fitted values and residuals as input and returns a `data.frame` with five numeric columns. These columns represent four scagnostics — "Monotonic", "Sparse", "Striped", and "Splines" — calculated using the `cassowaryr` package, as well as the number of observations. This approach is consistent with the training process of the computer vision models described in @li2024automated. If no `data.frame` is provided, the method will default to retrieving fitted values and residuals by calling `get_fitted_and_resid()`. 

Technically, any Keras-implemented computer vision model can be adapted to accept an image as the primary input and additional variables as secondary inputs by adding a data pre-processing layer before the actual input layer. If users wish to override `auxiliary()`, the output should be a `data.frame` with a single row and the number of columns such that its concatenation matches the number of parameters for the corresponding layer in the supplied Keras model.

```{r echo=TRUE}
checker$auxiliary()
```


### Null Residual Simulation {#sec-autovi-null-method}

A fundamental element of the automated residual assessment described in @li2024automated is comparing the VSS of null plots with that of the true residual plot. However, due to the variety of regression models, there is no universal method for simulating null residuals that are consistent with model assumptions. Fortunately, for classical normal linear regression models, null residuals can be effectively simulated using the residual rotation method, as outlined in @buja2009statistical. This process involves generating random draws from a standard normal distribution, regressing these draws on the original predictors, and then rescaling the resulting residuals by the ratio of the residual sum of squares to the that of the original linear regression model. Other regression models, such as `glm` (generalized linear model) and `gam` (generalized additive model), generally cannot use this method to efficiently simulate null residuals. Therefore, it is recommended that users override the `null_method()` to suit their specific model. The `null_method()` takes a fitted regression model as input, defaulting to the regression model stored in the checker, and returns a `tibble`.

```{r echo=TRUE}
checker$null_method()
```


### Plotting

Plotting is a crucial aspect of residual plot diagnostics because aesthetic elements like marker size, marker color, and auxiliary lines impact the presentation of information. There are computer vision models trained to handle images captured in various scenarios. For example, the VGG16 model [@simonyan2014very] can classify objects in images taken under different lighting conditions and is robust to image rotation. However, data plots are a special type of image as the plotting style can always be consistent if controlled properly. Therefore, we assume computer vision models built for reading residual plots will be trained with residual plots of a specific aesthetic style. In this case, it is best to predict plots using the same style for optimal performance. The plotting method `plot_resid()` handles this aspect. 

`plot_resid()` accepts a `data.frame` containing fitted values and residuals, along with several customization options: a `ggplot` theme, an `alpha` value to control the transparency of data points, a `size` value to set the size of data points, and a `stroke` value to define the thickness of data point edges. Additionally, it includes four Boolean arguments to toggle the display of axes, legends, grid lines, and a horizontal red line. By default, it replicates the style we used to generate the training samples for the computer vision models described in @li2024automated. In brief, the residual plot omits axis text and ticks, titles, and background grid lines, featuring only a red line at $y = 0$. It retains only the necessary components of a residual plot. If the computer vision model is trained with a different but consistent aesthetic style, `plot_resid()` should be overridden. 

The method returns a `ggplot` object (@fig-autovi-plot-resid), which can be saved as a PNG file in the following module. If no data is provided, the method will use `get_fitted_and_resid()` to retrieve the fitted values and residuals from the regression model stored in the checker.

```{r fig-autovi-plot-resid, echo=TRUE, fig.height=3, fig.width=4, fig.cap = "Residual plot of the regression model stored in the checker."}
checker$plot_resid()
```


To manually generate true residual plots, null plots, or bootstrapped residual plots, you can pass the corresponding `data.frame` produced by the `get_fitted_and_resid()`, `null_method()`, and `boot_method()` methods to the `plot_resid()` method, respectively.

### Plot Saving

Another key aspect of a standardized residual plot is its resolution. In @li2024automated, we used an image format of 420 pixels in height and 525 pixels in width. This resolution was chosen because the original set, consisting of 20 residual plots arranged in a four by five grid, was represented by an image of 2100 by 2100 pixels. The `save_plot()` method accepts a `ggplot` object as input and saves it as a PNG file to the location specified by the `path` argument. If no path is provided, the PNG file is saved to a temporary file.

```{r echo=TRUE}
checker$plot_resid() |> 
  checker$save_plot()
```

### Image Reading and Resizing

When training computer vision models, it is common to test various input sizes for the same architecture to identify the optimal setup. This involves preparing the original training image at a higher resolution than required and then resizing it to match the input size during training. The `autovi` package includes a class, `KERAS_WRAPPER`, to simplify this process. This Keras wrapper class features a method called `image_to_array()`, which reads an image as a `PIL` image using the `pillow` Python package, resizes it to the target input size required by the Keras model, and converts it to a `Numpy` array.

To construct a `KERAS_WRAPPER` object, you need to provide the Keras model as the main argument. However, users generally do not need to interact with this class directly, as the `autovi` checker automatically invokes its methods when performing VSS predictions. The `image_to_array()` method takes the path to the image file, the target height, and the target width as inputs and returns a `Numpy` array. If not specified, the target height and target width will be retrieved from the input layer of the Keras model by the `get_input_height()` and `get_input_width()` method of `KERAS_WRAPPER`. 

The following code example demonstrate the way to manually generate the true residual plot, save it as PNG file, and load it back as `Numpy` array.

```r
wrapper <- keras_wrapper(keras_model = checker$keras_model)  
input_array <- checker$plot_resid() |> 
  checker$save_plot() |>
  wrapper$image_to_array()
input_array$shape
```

```{r}
# If the Keras model can not be loaded
if (!file.exists("cached_data/autovi_check_demo.rds")) {
  wrapper <- keras_wrapper(keras_model = checker$keras_model)  
  input_array <- checker$plot_resid() |> 
    checker$save_plot() |>
    wrapper$image_to_array()
  input_array$shape
} else {
  cat("(1, 32, 32, 3)")
}
```



### Visual Signal Strength (VSS) Prediction

VSS, as discussed in @li2024automated, estimates the distance between the input residual plot and a theoretically good  residual plot. It can be defined in various ways, much like different methods for measuring the distance between two points. This will not impact the `autovi` infrastructure as long as the provided Keras model can predict the intended measure.

There are several ways to obtain VSS from the checker, with the most direct being the `vss()` method. By default, this method predicts the VSS for the true residual plot. If a `ggplot` or a `data.frame`, such as null residuals generated by the `null_method()`, is explicitly provided, the method will use that input to predict VSS accordingly. Note that if a `ggplot` is provided, auxiliary inputs must be supplied manually via the `auxiliary` argument, as we assume that auxiliary variables can not be computed directly from a `ggplot`.

Another way to obtain VSS is by calling the `check()` method. This comprehensive method perform extensive diagnostics on the true residual plot and store the VSS in the `check_result` field of the checker. Additionally, for obtaining VSS for null residual plots and bootstrapped residual plots, there are two specialized methods, `null_vss()` and `boot_vss()`, designed for this purpose respectively.

Calling the `vss()` method without arguments will predict the VSS for the true residual plot and return the result as a single-element `tibble`.

```r
checker$vss()
```

```{r}
if (!file.exists("cached_data/autovi_check_demo_2.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  saveRDS(checker$vss(), "cached_data/autovi_check_demo_2.rds")
  checker$vss()
} else {
  readRDS("cached_data/autovi_check_demo_2.rds")
}
```


Providing a `data.frame` of null residuals or a null residual plot yields the same VSS.


```r
null_resid <- checker$null_method()
checker$vss(null_resid)
```

```{r}
null_resid <- checker$null_method()

if (!file.exists("cached_data/autovi_check_demo_3.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  saveRDS(checker$vss(null_resid), "cached_data/autovi_check_demo_3.rds")
  checker$vss(null_resid)
} else {
  readRDS("cached_data/autovi_check_demo_3.rds")
}
```


```r
null_resid |>
  checker$plot_resid() |>
  checker$vss()
```

```{r}
readRDS("cached_data/autovi_check_demo_3.rds")
```

The `null_vss()` helper method primarily takes the number of null plots as input. If the user wants to use a ad hoc null simulation scheme, it can be provided via the `null_method` argument. Intermediate results, including null residuals and null plots, can be returned by enabling `keep_null_data` and `keep_null_plot`. The VSS, along with null residuals and null plots, will be stored in a `tibble` with three columns. The following code example demonstrates how to predict the VSS for five null residual plots while keeping the intermediate results.

```r
checker$null_vss(5L, 
                 keep_null_data = TRUE, 
                 keep_null_plot = TRUE)
```


```{r}
if (!file.exists("cached_data/autovi_check_demo_4.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  result <- checker$null_vss(5L, 
                             keep_null_data = TRUE, 
                             keep_null_plot = TRUE)
  saveRDS(result, "cached_data/autovi_check_demo_4.rds")
  result
} else {
  readRDS("cached_data/autovi_check_demo_4.rds")
}
```

The `boot_vss()` helper method is similar to `null_vss()`, with some differences in argument names. The following code example demonstrates how to predict the VSS for five bootstrapped residual plots while keeping the intermediate results.

```r
checker$boot_vss(5L,
                 keep_boot_data = TRUE,
                 keep_boot_plot = TRUE)
```

```{r}
if (!file.exists("cached_data/autovi_check_demo_5.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  result <- checker$boot_vss(5L, 
                             keep_boot_data = TRUE, 
                             keep_boot_plot = TRUE)
  saveRDS(result, "cached_data/autovi_check_demo_5.rds")
  result
} else {
  readRDS("cached_data/autovi_check_demo_5.rds")
}
```

### $p$-value Computation

Once we have obtained the VSS from both the true residual plot and the null plots, we can compute the $p$-value. This $p$-value represents the ratio of plots with VSS greater than or equal to that of the true residual plot. We can perform this calculation using the `check()` method. The main inputs for this method are the number of null plots and the number of bootstrapped plots to generate. If you need to access intermediate residuals and plots, you can enable the `keep_data` and `keep_plot` options. The method stores the final result in the `check_result` field of the object. To obtain the p-value using the `check()` method, you can use the following code.

```r
checker$check(boot_draws = 100L, null_draws = 100L)
checker$check_result$p_value
```

```{r}
if (!file.exists("cached_data/autovi_check_demo_6.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  checker$check(boot_draws = 100L, null_draws = 100L)
  saveRDS(checker$check_result, "cached_data/autovi_check_demo_6.rds")
} else {
  checker$check_result <- readRDS("cached_data/autovi_check_demo_6.rds")
}

checker$check_result$p_value
```


## Summary Plots

After executing the `check()` method, `autovi` offers two visualization options for the assessment result through the `summary_plot()` method, including the density plot and the rank plot. We have already discussed and interpreted the density plot in @sec-autovi-usage. Here, we would like to highlight the flexibility in choosing which elements to display in the density plot as shown in @fig-autovi-summary-plot-option. For instance, you can omit the bootstrapped distribution by setting `boot_dist` to `NULL`. Similarly, you can hide the null distribution (`null_dist`), the $p$-value (`p_value`), or the likelihood ratio (`likelihood_ratio`) as needed. The following example demonstrates how to create a summary plot without the results from bootstrapped plots.

```{r fig-autovi-summary-plot-option, echo=TRUE, fig.cap = "Density plot of the VSS for null plots."}
checker$summary_plot(boot_dist = NULL,
                     likelihood_ratio = NULL)
```

This customization allows you to focus on specific aspects of the assessment, tailoring the visualization to your analytical needs.

The rank plot (@fig-autovi-rank-plot), creating by setting `type` to "rank", is a bar plot where the $x$-axis represents the rank and the $y$-axis shows the VSS. The bar that is coloured in red corresponding to the VSS of the true residual plot. By examining the rank plot, you can intuitively understand how the observed VSS compares to the null VSSs and identify any outliers in the null distribution.

```{r fig-autovi-rank-plot, echo=TRUE, fig.cap = "Rank plot of the VSS for null plots."}
checker$summary_plot(type = "rank")
```


## Feature Extraction

In addition to predicting VSS and computing $p$-values, `autovi` offers methods to extract features from any layer of the Keras model. To see which layers are available in the current Keras model, you can use the `list_layer_name()` method from the `KERAS_WRAPPER` class.

The following code example lists the layer names of the currently used Keras model:

```r
wrapper <- keras_wrapper(checker$keras_model)
wrapper$list_layer_name()
```

```{r}
if (!file.exists("cached_data/autovi_check_demo_8.rds")) {
  wrapper <- keras_wrapper(get_keras_model("vss_phn_32"))
  result <- wrapper$list_layer_name()
  saveRDS(result, "cached_data/autovi_check_demo_8.rds")
} else {
  readRDS("cached_data/autovi_check_demo_8.rds")
}
```

Among these layers, the "global_max_pooling2d" layer is a 2D global max pooling layer that outputs the results from the last convolutional blocks. As @simonyan2014very noted, all preceding convolutional blocks can be viewed as a large feature extractor. Consequently, the output from this layer provides features that can be utilized for various purposes, such as performing transfer learning.

To obtain the features, provide the layer name using the `extract_feature_from_layer` argument in the `predict()` method. This will return a `tibble` with the VSS and all features extracted from that layer. Each row corresponds to one plot. The features will be flattened into 2D and named with the prefix "f_" followed by a number from one to the total number of features.

```r
checker$plot_resid() |>
  checker$save_plot() |>
  wrapper$image_to_array() |>
  wrapper$predict(auxiliary = checker$auxiliary(),
                  extract_feature_from_layer = "global_max_pooling2d")
```

```{r}
if (!file.exists("cached_data/autovi_check_demo_7.rds")) {
  checker$keras_model <- get_keras_model("vss_phn_32") 
  result <- checker$plot_resid() |>
    checker$save_plot() |>
    wrapper$image_to_array() |>
    wrapper$predict(auxiliary = checker$auxiliary(),
                    extract_feature_from_layer = "global_max_pooling2d")
  saveRDS(result, "cached_data/autovi_check_demo_7.rds")
} else {
  readRDS("cached_data/autovi_check_demo_7.rds")
}
```


Alternatively, the `AUTO_VI` class provides a way to extract features using the `vss()` method. This method is essentially a high-level wrapper around the `predict()` method of `KERAS_WRAPPER`, but it offers a more straightforward interface and better default arguments.

The results from the previous code example can be replicated with a single line of code as shown below.

```r
checker$vss(extract_feature_from_layer = "global_max_pooling2d")
```

```{r}
readRDS("cached_data/autovi_check_demo_7.rds")
```


The argument `extract_feature_from_layer` is also available in other functions that build on the `vss()` method, including `null_vss()`, `boot_vss()`, and `check()`.


## Trained Model Hosting {#sec-trained-model-hosting}

The trained computer vision models described in @li2024automated are hosted on a GitHub repository at [https://github.com/TengMCing/autovi_data](https://github.com/TengMCing/autovi_data). Currently, there are six models available. You can view them by calling `list_keras_model()`, which will return a `tibble` showing the input shape and a description of each model.

```{r echo = TRUE}
list_keras_model() |>
  str()
```

The `get_keras_model()` function can be used to download a model to a temporary directory and load it into memory using `TensorFlow`. It requires only the model name, which is the value in the first column of the `tibble` returned by `list_keras_model()`.
-->

# Web interface: autovi.web {#sec-autovi-web}

The `autovi.web` shiny application extends the functionality of `autovi` by offering a user-friendly web interface for automated residual plot assessment. This eliminates the common challenges associated with software installation, so users can avoid managing Python environments or handling version requirements for R libraries. The platform is cross-platform and accessible on various devices and operating systems, making it suitable even for users without R programming experience. Additionally, updates are managed centrally, ensuring that users always have access to the latest features.
<!--The `autovi.web` interface is available at [autoviweb.netlify.app](autoviweb.netlify.app).--> This section discusses the implementation based on `autovi.web` version 0.1.0.

## Implementation

The interface `autovi.web` is built using the `shiny` [@shiny] and `shinydashboard` [@shinydashboard] R packages. Hosted on the [shinyapps.io](https://www.shinyapps.io) domain, the application is accessible through any modern web browser. The R packages `htmltools` [@htmltools] and `shinycssloaders` [@shinycssloaders] are used to render markdown documentation in shiny application, and for loading animations for shiny widgets, respectively.

Determining the best way to implement the backend was difficult. In our initial planning for `autovi.web`, we considered implementing the entire web application using the `webr` framework [@webr], which would have allowed the entire application to run directly in the user's browser. However, `webr` does not support packages which use compiled fortran code, which is required by `splancs` [@splancs], a dependency of `autovi`. In the future, it is possible that a working Emscripten [@zakai2011emscripten] version of this package may allow full `webr` support.

We also explored the possibility of implementing the web interface using frameworks built on other languages, such as Python. However, server hosting domains that natively support Python servers typically do not have the latest version of R installed. Additionally, calling R from Python is typically done using the `rpy2` Python library [@rpy2], but this approach can be awkward when dealing with language syntax related to non-standard evaluation. Another option we considered was renting a server where we could have full control, such as those provided by cloud platforms like Google Cloud Platform (GCP) or Amazon Web Services (AWS). However, deploying and maintaining the server securely requires some expertise. Ultimately, the most practical solution was to use the `shiny` and `shinydashboard` frameworks, which are well-established in the R community and offer a solid foundation for web application development.

The server-side configuration of `autovi.web` is carefully designed to support its functionality. Most required Python libraries, including `pillow` and `numpy`, are pre-installed on the server. These libraries are integrated into the Shiny application using the `reticulate` package, which provides an interface between R and Python.

Due to shinyapps.io's resource policy, inactive servers enter sleep mode, clearing the local Python environment. When reactivated for a new session, libraries must be reinstalled. While this ensures a clean environment for each session, it may lead to slightly longer loading times for the first user after a period of inactivity.

In contrast to `autovi`, `autovi.web` leverages `TensorFlow.js`, a JavaScript library that allows the execution of machine learning models directly in the browser. This choice enables native browser execution, enhancing compatibility across different user environments, and shifts the computational load from the server to the client-side. `TensorFlow.js` also offers better scalability and performance, especially when dealing with resource-intensive computer vision models on the web. 

While `autovi` requires downloading the pre-trained computer vision models from GitHub, these models in ".keras" file format are incompatible with `TensorFlow.js`. Therefore, we extract and store the model weights in JSON files and include them as extra resources in the Shiny application. When the application initializes, `TensorFlow.js` rebuilds the computer vision model using these pre-stored weights.

To allow communication between `TensorFlow.js` and other components of the Shiny application, the `shinyjs` R package [@shinyjs] is used. This package allows calling custom JavaScript code within the Shiny framework. The specialized JavaScript code for initializing `TensorFlow.js` and calling `TensorFlow.js` for VSS prediction is deployed alongside the Shiny application as additional resources.

<!-- ## Design {#sec-autovi-web-design}-->

```{r fig-autovi-web, out.width = "100%", fig.cap = "Overview of the `autovi.web` graphical user interface (GUI). This default view may change based on user interactions. Region 1 is the sidebar menu, containing the residual assessment tab and the information tab. Region 2 is the data upload panel, where users can provide a CSV file and specify the type of data it contains. Region 3 includes dropdown menus for selecting the columns to be analyzed, a slider to control the number of bootstrapping samples, and a numeric input box for setting the simulation seed. Region 4 displays the initialization status and offers a button to start the analysis. Region 5 is empty in the default view but will be populated with results once the analysis is started. ", eval=FALSE}
knitr::include_graphics("figures/autovi_web.png")
```

<!--The focus of `autovi.web` is on providing a straightforward and clean user interface. An overview of the graphical user interface of `autovi.web` is provided in @fig-autovi-web. This is the default view of the web application, and there are five regions that user can mainly interact with. Region 1 of @fig-autovi-web is a sidebar menu which can switch between the analysis page and the information page. The analysis page is the focus of this section. 

Region 2 of @fig-autovi-web is a panel for data uploading and CSV type selection. Clicking the "upload CSV" button opens a window where the user can select a file from their local system. The data status displayed above the button provides information about the number of rows and columns in the current dataset. Additionally, there are two example datasets available beneath the "upload CSV" button: one is a lineup example using a CSV file with three columns, and the other is a single plot example using a CSV file with two columns. More details about these example datasets are be discussed in @sec-autovi-web-workflow.

While the `autovi` package typically expects a fitted regression model object provided by the user, this approach is impractical for a web interface. Saving the R model object to the filesystem involves extra steps and requires users to have specific knowledge, which does not align with the goal of the web application. Moreover, the regression model object may contain sensitive, non-shareable data, making it unsuitable for uploading. Additionally, model objects are often unnecessarily large, containing extra information not needed for residual diagnostics. In contrast, a CSV file is easier to generate using various software programs, not just R. CSV files are widely accepted and can be easily viewed and modified using common desktop applications like Excel. They are generally less sensitive than raw data, as they exclude most information about the predictors. 

The web application is designed to assess either a single residual plot or a lineup of residual plots. Therefore, it accepts only two types of CSV files: one with at least two columns representing the fitted values and residuals of a single residual plot, and another with at least three columns, where the additional column serves as the label or identifier for a lineup of multiple residual plots. For a single residual plot, 19 null plots are generated by simulating normal random draws from a distribution with the same variance as the original residual plot, and comparisons are made with the original residual plot. For a lineup, comparisons are made among the plots within the lineup. After uploading the CSV file, the user must select the correct format to ensure the web interface interprets the data correctly. -->

```{r fig-autovi-web-type, out.width = "100%", fig.cap = "The panels for selecting target columns and simulation settings are updated when a different CSV type is selected in the left panel. Compared to @fig-autovi-web, where the CSV type is a single residual plot, choosing a CSV type that includes a lineup of multiple residual plots adds a dropdown menu for specifying a column for the residual plot identifier. Additionally, an optional dropdown menu for specifying the true residual plot identifier will appear under the simulation settings.", eval=FALSE}
knitr::include_graphics("figures/autovi_web_type.png")
```

<!--Region 3 of @fig-autovi-web is a panel for column selection and simulation settings. As shown in @fig-autovi-web, if the CSV type is set to a single residual plot, there will be two dropdown menus for specifying the columns for fitted values and residuals, respectively. The default variable names for these columns are `.fitted` and `.resid`. After uploading the CSV file, the content of these dropdown menus will be updated to reflect the existing columns in the dataset. As displayed in @fig-autovi-web-type, for the CSV type that is a lineup of multiple residual plots, an additional dropdown menu will appear for specifying the column of residual plot labels. The default variable name for this column is `.sample`. If this variable name does not exist in the dataset, the dropdown menu will remain empty, allowing the user to specify the correct column. The number of levels for each option in this dropdown menu will be displayed to help avoid the selection of a variable with too many levels, which could significantly slow down the application due to extensive computation.

Under the simulation settings, there is a slider for specifying the number of bootstrapped samples needed for the assessment. A higher value on this slider will result in a more accurate bootstrap distribution estimation, though it will require more computation time. The simulation seed can be set in a numeric input box below the slider to control the reproducibility of the assessment. By default, a random seed is set each time the web page is refreshed. When the CSV type is a lineup of multiple residual plots, an optional dropdown menu will appear next to the simulation seed input box, allowing the user to specify an identifier for the true residual plot. If no label is provided for the true residual plot, the assessment will only estimate the VSS for each residual plot in the lineup, without providing a $p$-value, as it cannot be computed. Consequently, some result panels may be missing due to insufficient information. This option is useful when the lineup consists solely of null plots or if the user simply wants to obtain the VSS for multiple residual plots.

Region 4 of @fig-autovi-web is the panel for triggering the assessment. It contains a large play button to start the assessment. Above the play button, a text message displays the status of `TensorFlow.js`, allowing users to monitor whether the JavaScript library and Keras model have been loaded correctly. The play button will remain disabled until both the data status in Region 1 and the `TensorFlow.js` status in Region 4 indicate that everything is ready, with both showing a green status.

Once the play button is clicked, region 5 of @fig-autovi-web will be populated with panels displaying the assessment results. Generally, there will be four result panels, as shown in @fig-autovi-web-result and @fig-autovi-web-result2. 
-->


```{r fig-autovi-web-result, out.width = "100%", fig.cap = "The first two panels of results from the automated residual assessment are shown. The application provides four results panels in total, and these screenshots display the first two. In region 1, there is an interactive table detailing the VSS, with a summary of the analysis provided in the paragraph below. Region 2 displays a lineup of residual plots.", eval=FALSE}
knitr::include_graphics("figures/autovi_web_result.png")
```

```{r fig-autovi-web-result2, out.width = "100%", fig.cap = "The last two panels of results from the automated residual assessment are shown. The application provides four results panels in total, and these screenshots display the final two. Region 1 presents a density plot comparing the bootstrapped VSS with the null VSS. Region 2 includes an attention map of the true residual plot.", eval=FALSE}
knitr::include_graphics("figures/autovi_web_result2.png")
```

```{r fig-autovi-web-gradient-hide, out.width = "50%", fig.cap = "The attention map is hidden if the assessment indicates a $p$-value greater than 0.05. A button is available to toggle the display of the attention map.", eval=FALSE}
knitr::include_graphics("figures/autovi_web_gradient_hide.png")
```


<!-- Region 6 of @fig-autovi-web-result contains an interactive table created with the R package `DT` [@dt], which provides the VSS. This table includes four columns: `.sample`, `vss`, `rank`, and `null`. The `.sample` column shows the residual plot labels. For a CSV type that is a lineup, these labels are taken from an identifier column in the dataset specified by the user. In the case of the CSV type is a single residual plot, labels are automatically generated from 1 to 20, with the true residual plot receiving a randomly assigned label. The `vss` column displays the VSS for each residual plot, rounded to three decimal places. The `rank` column indicates the ranking of each residual plot based on VSS. The `null` column reveals whether the plot is a null plot. For the CSV type that is a single residual plot, only the true residual plot will have "false" in this column, while all other plots will be marked "true." For the CSV type that is a lineup, if the true residual plot identifier has not been provided, this column will show "NA" to represent missing values. If the identifier is provided by user, the column behaves as if the CSV type is a single residual plot.

The `DT` table provides several interactive features. Users can download the table in four formats, including text, CSV, Excel, and PDF, using the buttons located above the table. Additionally, the table is searchable via the text input field also positioned above it. Below the table, a text message displays the $p$-value of the assessment for the true residual plot and summarizes the number of null plots with VSS greater than that of the true residual plot. This helps the user determine whether the true residual plot shows visual patterns that suggest model violations.

Region 7 of @fig-autovi-web-result provides a lineup of plots corresponding to each `.sample` value from the table in Region 6. Due to space limitations, a maximum of 20 residual plots will be displayed, ensuring that the true residual plot, if known, will be included in the lineup. The plots are generated using `ggplot2`, the same as in `autovi`. Users can perform a visual test with this lineup to check if the true residual plot is distinguishable from the other plots, helping to determine the significance of model violations.

Region 8 of @fig-autovi-web-result2 displays the density plot for bootstrapped VSS and null VSS. The densities are shown in distinct colors that are friendly for colorblind users. A solid vertical line marks the VSS of the true residual plot, while rug lines at the bottom of the plot provide a clearer view of individual cases. Below the plot, a text message indicates the number and percentage of bootstrapped residual plots that would be rejected by the visual test when compared to the null plots. Note that the bootstrapped residual plots in this application are generated differently from `autovi`. Since we do not have the R model object, we can not refit the regression model with bootstrapped data. Instead, we bootstrap the residuals of the true residual plot directly to obtain bootstrapped residual plots. As as result, this panel will disappear when the true residual plot is unknown.

Region 9 of @fig-autovi-web-result2 displays an attention map for the true residual plot, generated by computing the gradient of the Keras model's output with respect to the greyscale input of the plot. The attention map helps to understand how the Keras model predicts VSS and which areas it is focusing on. We use a greyscale input because it is easier to generate a clear attention map in this format, and it usually conveys all the essential information, as most of the important details of the plot are drawn in black. If the $p$-value of the true residual plot is greater than 0.05, checking the attention map is not necessary. However, to provide users with the option to review it if they wish, a button will be available, as shown in @fig-autovi-web-gradient-hide. This button allows users to toggle the display of the attention map.-->

## Usage {#sec-autovi-web-workflow}

The workflow of `autovi.web` is designed to be straightforward, with numbered steps displayed in each panel. There are two example datasets provided by the web application. The single residual plot example uses the `dino` dataset from the R package `datasauRus` [@datasaurus]. The lineup example uses residuals from a simulated regression model that has a non-linearity issue. We walk through the lineup example to further demonstrate the workflow of the web application.

### Reading data and setting parameters

The user can select to upload data as either a single set of residuals and fitted values in a two (or more) column CSV file or a pre-computed lineup of residuals and null datasets in a three (or more) column CSV file (i.e. multiple sets of residuals and fitted values with a column indicating the set label). Here we illustrate use with lineup example data sets (@fig-autovi-web-setup).  To use the lineup example data, click the "Use Lineup Example" button. The data status will then update to show the number of rows and columns in the dataset, and the CSV type will automatically be selected to the correct option. Since the example dataset follows the variable naming conventions assumed by the web application, the columns for fitted values, residuals, and labels of residual plots are automatically mapped such that the column named as `.fitted` is mapped to fitted values, `.resid` is mapped to residuals and if applicable, `.sample` to labels of the residual set (middle image). If the user is working with a custom dataset, these options must be set accordingly. Whenever a data containing a lineup, the user must manually select the label for the true residual plot, otherwise the web application does not provide all the results. The last step is to click the play button (right image) to start the assessment.

```{r fig-autovi-web-setup, out.width = "100%", fig.cap = 'To begin the workflow for `autovi` using the lineup example dataset, the user clicks the "Use Lineup Example" button (left) to load the example dataset, during which the data status and CSV type will be automatically updated. The user must manually select the label for the true residual plot (middle) to compute further results. The user initiates the assessment of the lineup example data by clicking the run button (right).'}
magick::image_read_pdf("figures/autovi_web_setup.pdf")
```


```{r fig-autovi-web-workflow-example1, out.width = "80%", fig.cap = 'To begin the workflow for `autovi` using the lineup example dataset, the user clicks the "Use Lineup Example" button to load the example dataset, during which the data status and CSV type will be automatically updated.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_1.pdf")
```


```{r fig-autovi-web-workflow-example2, out.width = "80%", fig.cap = 'After clicking the button in @fig-autovi-web-workflow-example1, the target columns are selected automatically, though the user must manually select the label for the true residual plot, as the web application permits assessment without this label.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_2.pdf")
```

```{r fig-autovi-web-workflow-example3, out.width = "55%", fig.cap = 'After finishing the required steps in @fig-autovi-web-workflow-example1 and @fig-autovi-web-workflow-example2, the user initiates the assessment of the lineup example data by clicking the run button.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_3.pdf")
```

### Results provided

Results are provided in multiple panels.<!-- as displayed in @fig-autovi-web-workflow-example3, @fig-autovi-web-workflow-example4, @fig-autovi-web-workflow-example5 and @fig-autovi-web-workflow-example6. In @fig-autovi-web-workflow-example3--> The first row of the table [@fig-autovi-web-lineup] is the most crucial to check, as it provides the VSS and the rank of the true residual plot among the other plots. The summary text beneath the table provides the $p$-value, which can be used for quick decision-making. The lineup is for manual inspection, and the user should see if the true residual plot is visually distinguishable from the other plots, to confirm if the model violation is serious. 

The density plot in @fig-autovi-web-distributions offers a more robust result, allowing the user to compare the distribution of bootstrapped VSS with the distribution of null VSS. Finally, the grayscale attention map (right image) can be used to check if the target visual features, like the non-linearity present in the lineup example, are captured by the computer vision model, ensuring the quality of the assessment. The attention map is the gradient of the model output with respect to the grayscale image input, indicating the sensitivity of the output to each pixel.

```{r fig-autovi-web-lineup, out.width = "100%", fig.cap = 'Results for the lineup. The VSS of the true residual plot is displayed in the first row of the table of VSS values for all the null plots (left image), with a summary text beneath the table providing the $p$-value to aid in decision-making. A lineup of residual plots allows for manual inspection (right image). '}
magick::image_read_pdf("figures/autovi_web_lineup.pdf")
```

```{r fig-autovi-web-distributions, out.width = "100%", fig.cap = 'Summaries assessing the strength of the pattern and which elements of the plot contribute. The density plot helps verify if the bootstrapped distribution differs from the null distribution (left image). The attention map (right image) offers insights into whether the computer vision model has captured the intended visual features of the true residual plot.'}
magick::image_read_pdf("figures/autovi_web_distributions.pdf")
```


```{r fig-autovi-web-workflow-example4, out.width = "100%", fig.cap = 'The VSS of the true residual plot is displayed in the first row of the table, with a summary text beneath the table providing the $p$-value to aid in decision-making.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_4.pdf")
```

```{r fig-autovi-web-workflow-example5, out.width = "100%", fig.cap = 'A lineup of residual plots allows for manual inspection.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_5.pdf")
```

```{r fig-autovi-web-workflow-example6, out.width = "100%", fig.cap = 'The density plot helps verify if the bootstrapped distribution differs from the null distribution.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_6.pdf")
```

```{r fig-autovi-web-workflow-example7, out.width = "100%", fig.cap = 'The attention map offers insights into whether the computer vision model has captured the intended visual features of the true residual plot.', eval=FALSE}
magick::image_read_pdf("figures/autovi_web_workflow_7.pdf")
```

# Conclusions {#sec-autovi-conclusion}

This paper presents new regression diagnostics software, the R package `autovi` and its accompanying web interface, `autovi.web`. It addresses a critical gap in the current landscape of statistical software. While regression tools are widely available, effective and efficient diagnostic methods have lagged behind, particularly in the field of residual plot interpretation.

The `autovi` R package, introduced in this paper, automates the assessment of residual plots by incorporating a computer vision model, reducing reliance on time-consuming and potentially inconsistent human interpretation. This automation improves the efficiency of the diagnostic process and promotes consistency in model evaluation across different users and studies.

The development of the accompanying Shiny app, `autovi.web`, expands access to these advanced diagnostic tools, by providing a user-friendly interface. It makes automated residual plot assessment accessible to a broader audience, including those who may not have extensive programming experience. This web-based solution effectively addresses the potential barriers to adoption, such as complex dependencies and installation requirements, that are often associated with advanced statistical software.

The combination of `autovi` and `autovi.web` offers a comprehensive solution to the challenges of residual plot interpretation in regression analysis. These tools have the potential to significantly improve the quality and consistency of model diagnostics across various fields, from academic research to industry applications. By automating a critical aspect of model evaluation, they allow researchers and analysts to focus more on interpreting results and refining models, rather than grappling with the intricacies of plot assessment.

The framework established by `autovi` and `autovi.web` opens up exciting possibilities for further research and development. Future work could explore the extension of these automated assessment techniques to other types of diagnostic plots and statistical models, potentially revolutionizing how we approach statistical inference using visual displays more broadly.

# Resources and supplementary material

The current version of `autovi` can be installed from CRAN, and source code for both packages are available at [`github.com/TengMCing/autovi`](https://github.com/TengMCing/autovi) and [`github.com/TengMCing/autovi_web`](https://github.com/TengMCing/autovi_web) respectively. The web interface is available from [`autoviweb.netlify.app`](https://autoviweb.netlify.app/). 

This paper is reproducibly written using Quarto [@Allaire_Quarto_2024] powered by Pandoc [@MacFarlane_Pandoc] and pdfTeX. The full source code to reproduce this paper is available at [`github.com/TengMCing/autovi_paper`](https://github.com/TengMCing/autovi_paper).

These `R` packages were used for the work: `tidyverse` [@tidyverse], `lmtest` [@lmtest], `kableExtra` [@kableextra], `patchwork` [@patchwork], `rcartocolor` [@rcartocolor], `glue` [@glue],  `here` [@here], `magick` [@magick], `yardstick` [@yardstick] and `reticulate` [@reticulate]. 
